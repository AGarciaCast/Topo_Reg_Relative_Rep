{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Code based on AE with pytorch lighting tutorial: https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial9/AE_CIFAR10.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SRrkQeIoSjuQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\alexg\\AppData\\Local\\Temp\\ipykernel_61436\\2116438814.py:11: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
            "  set_matplotlib_formats('svg', 'pdf') # For export\n",
            "Global seed set to 42\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import numpy as np \n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgb\n",
        "import matplotlib\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "import seaborn as sns\n",
        "sns.reset_orig()\n",
        "sns.set()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "# PyTorch Lightning\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "\n",
        "# Tensorboard extension (for visualization purposes later)\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
        "DATASET_PATH = \"./data\"\n",
        "# Path to the folder where the pretrained models are saved\n",
        "CHECKPOINT_PATH = \"./saved_models/ae_sim\"\n",
        "\n",
        "# Setting the seed\n",
        "pl.seed_everything(42)\n",
        "\n",
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ktyT-w6-SjuR",
        "outputId": "2dcf9e8a-d9a4-4aee-e715-c27d8fa560e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Global seed set to 42\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# Transformations applied on each image => only make them a tensor\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,))])\n",
        "\n",
        "# Loading the training dataset. We need to split it into a training and validation part\n",
        "train_dataset = MNIST(root=DATASET_PATH, train=True, transform=transform, download=True)\n",
        "pl.seed_everything(42)\n",
        "print(train_dataset.data.shape)\n",
        "train_set, val_set = torch.utils.data.random_split(train_dataset, [50000, 10000])\n",
        "\n",
        "# Loading the test set\n",
        "test_set = MNIST(root=DATASET_PATH, train=False, transform=transform, download=True)\n",
        "\n",
        "# We define a set of data loaders that we can use for various purposes later.\n",
        "train_loader = data.DataLoader(train_set, batch_size=256, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
        "val_loader = data.DataLoader(val_set, batch_size=256, shuffle=False, drop_last=False, num_workers=4)\n",
        "test_loader = data.DataLoader(test_set, batch_size=256, shuffle=False, drop_last=False, num_workers=4)\n",
        "\n",
        "NUM_BATCHES_TRAIN = len(train_loader)\n",
        "\n",
        "def get_train_images(num):\n",
        "    return torch.stack([train_dataset[i][0] for i in range(num)], dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 300"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lv4EbhdMSjuS"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, \n",
        "                 num_input_channels : int, \n",
        "                 base_channel_size : int, \n",
        "                 latent_dim : int,\n",
        "                 linear_hidden_dims: list, \n",
        "                 act_fn : object = nn.GELU):\n",
        "        \"\"\"\n",
        "        Inputs: \n",
        "            - num_input_channels : Number of input channels of the image. For CIFAR, this parameter is 3\n",
        "            - base_channel_size : Number of channels we use in the first convolutional layers. Deeper layers might use a duplicate of it.\n",
        "            - latent_dim : Dimensionality of latent representation z\n",
        "            - act_fn : Activation function used throughout the encoder network\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        c_hid = base_channel_size\n",
        "        layers =  [nn.Conv2d(num_input_channels, c_hid, kernel_size=3, padding=3, stride=2), # 28x28 => 16x16\n",
        "            act_fn(),\n",
        "            nn.Conv2d(c_hid, c_hid, kernel_size=3, padding=1),\n",
        "            act_fn(),\n",
        "            nn.Conv2d(c_hid, 2*c_hid, kernel_size=3, padding=1, stride=2), # 16x16 => 8x8\n",
        "            act_fn(),\n",
        "            nn.Conv2d(2*c_hid, 2*c_hid, kernel_size=3, padding=1),\n",
        "            act_fn(),\n",
        "            nn.Conv2d(2*c_hid, 2*c_hid, kernel_size=3, padding=1, stride=2), # 8x8 => 4x4\n",
        "            act_fn(),\n",
        "            nn.Flatten(), # Image grid to single feature vector\n",
        "            ]\n",
        "        \n",
        "        layer_sizes = [2*16*c_hid] + linear_hidden_dims\n",
        "        for layer_index in range(1, len(layer_sizes)):\n",
        "            layers += [nn.Linear(layer_sizes[layer_index-1],\n",
        "                                 layer_sizes[layer_index]),\n",
        "                        act_fn()]\n",
        "        \n",
        "        layers += [nn.Linear(layer_sizes[-1], latent_dim),\n",
        "                   nn.Identity()]\n",
        "        \n",
        "        self.net = nn.ModuleList(layers)\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        for blk in self.net:\n",
        "            x = blk(x)\n",
        "            \n",
        "        return x\n",
        "    \n",
        "    def detailed_forward(self, x):\n",
        "        res = [x]\n",
        "        for blk in self.net:\n",
        "            x = blk(x)\n",
        "            res.append(x.detach().reshape(x.shape[0], -1))\n",
        "            \n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Hq87XZ47SjuS"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, \n",
        "                 num_input_channels : int, \n",
        "                 base_channel_size : int, \n",
        "                 latent_dim : int, \n",
        "                 linear_hidden_dims : list,\n",
        "                 act_fn : object = nn.GELU):\n",
        "        \"\"\"\n",
        "        Inputs: \n",
        "            - num_input_channels : Number of channels of the image to reconstruct. For CIFAR, this parameter is 3\n",
        "            - base_channel_size : Number of channels we use in the last convolutional layers. Early layers might use a duplicate of it.\n",
        "            - latent_dim : Dimensionality of latent representation z\n",
        "            - act_fn : Activation function used throughout the decoder network\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        c_hid = base_channel_size\n",
        "        \n",
        "        layer_sizes =  [latent_dim] + linear_hidden_dims + [2*16*c_hid]\n",
        "        linear_layers = []\n",
        "        for layer_index in range(1, len(layer_sizes)):\n",
        "            linear_layers += [nn.Linear(layer_sizes[layer_index-1],\n",
        "                                 layer_sizes[layer_index]),\n",
        "                        act_fn()]\n",
        "        \n",
        "        self.linear = nn.ModuleList(linear_layers)\n",
        "        \n",
        "        self.net = nn.ModuleList([\n",
        "            nn.ConvTranspose2d(2*c_hid, 2*c_hid, kernel_size=3, output_padding=1, padding=1, stride=2), # 4x4 => 8x8\n",
        "            act_fn(),\n",
        "            nn.Conv2d(2*c_hid, 2*c_hid, kernel_size=3, padding=1),\n",
        "            act_fn(),\n",
        "            nn.ConvTranspose2d(2*c_hid, c_hid, kernel_size=3, output_padding=1, padding=1, stride=2), # 8x8 => 16x16\n",
        "            act_fn(),\n",
        "            nn.Conv2d(c_hid, c_hid, kernel_size=3, padding=1),\n",
        "            act_fn(),\n",
        "            nn.ConvTranspose2d(c_hid, num_input_channels, kernel_size=3, output_padding=1, padding=3, stride=2), # 16x16 => 28x28\n",
        "            nn.Tanh() # The input images is scaled between -1 and 1, hence the output has to be bounded as well\n",
        "        ])\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = x.reshape(x.shape[0], -1, 4, 4)\n",
        "        x = self.net(x)\n",
        "        return x\n",
        "    \n",
        "    def forward(self, x):\n",
        "        for blk in self.linear:\n",
        "            x = blk(x)\n",
        "        \n",
        "        x = x.reshape(x.shape[0], -1, 4, 4)\n",
        "        \n",
        "        for blk in self.net:\n",
        "            x = blk(x)\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def detailed_forward(self, x):\n",
        "        res = []\n",
        "        \n",
        "        for blk in self.linear:\n",
        "            x = blk(x)\n",
        "            res.append(x.detach())\n",
        "            \n",
        "        \n",
        "        x = x.reshape(x.shape[0], -1, 4, 4)\n",
        "        \n",
        "        for blk in self.net:\n",
        "            x = blk(x)\n",
        "            res.append(x.detach().reshape(x.shape[0], -1))\n",
        "            \n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, \n",
        "                 base_channel_size: int, \n",
        "                 latent_dim: int, \n",
        "                 linear_hidden_dims : list = [],\n",
        "                 encoder_class : object = Encoder,\n",
        "                 decoder_class : object = Decoder,\n",
        "                 num_input_channels: int = 3, \n",
        "                 ):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Creating encoder and decoder\n",
        "        self.encoder = encoder_class(num_input_channels, base_channel_size, latent_dim, linear_hidden_dims)\n",
        "        self.decoder = decoder_class(num_input_channels, base_channel_size, latent_dim, linear_hidden_dims[::-1])\n",
        "    \n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        x_hat = self.decoder(z)\n",
        "        \n",
        "        return x_hat \n",
        "        \n",
        "    def detailed_forward(self, x):\n",
        "        \"\"\"\n",
        "        The forward function takes in an image and returns the reconstructed image\n",
        "        \"\"\"\n",
        "        z = self.encoder.detailed_forward(x)\n",
        "        x_hat = self.decoder.detailed_forward(z[-1])\n",
        "        return z + x_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "55W-rGDHSjuS"
      },
      "outputs": [],
      "source": [
        "class LitAutoencoder(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, \n",
        "                 base_channel_size: int, \n",
        "                 latent_dim: int, \n",
        "                 seed : int =42,\n",
        "                 linear_hidden_dims : list = [],\n",
        "                 encoder_class : object = Encoder,\n",
        "                 decoder_class : object = Decoder,\n",
        "                 num_input_channels: int = 3, \n",
        "                 width: int = 32, \n",
        "                 height: int = 32):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Saving hyperparameters of autoencoder\n",
        "        self.save_hyperparameters() \n",
        "        \n",
        "        pl.seed_everything(seed)\n",
        "\n",
        "        # Creating encoder and decoder\n",
        "        self.net = Autoencoder(base_channel_size, \n",
        "                               latent_dim,\n",
        "                               linear_hidden_dims,\n",
        "                               encoder_class,\n",
        "                               decoder_class,\n",
        "                               num_input_channels)\n",
        "        \n",
        "        # Example input array needed for visualizing the graph of the network\n",
        "        self.example_input_array = torch.zeros(2, num_input_channels, width, height)\n",
        "    \n",
        "    def forward(self, x):\n",
        "       \n",
        "        return self.net(x) \n",
        "        \n",
        "    def detailed_forward(self, x):\n",
        "        \"\"\"\n",
        "        The forward function takes in an image and returns a list of all the activations\n",
        "        \"\"\"\n",
        "        \n",
        "        return self.net.detailed_forward(x)\n",
        "    \n",
        "    def _get_reconstruction_loss(self, batch):\n",
        "        \"\"\"\n",
        "        Given a batch of images, this function returns the reconstruction loss (MSE in our case)\n",
        "        \"\"\"\n",
        "        x, _ = batch # We do not need the labels\n",
        "        x_hat = self.forward(x)\n",
        "        loss = F.mse_loss(x, x_hat, reduction=\"none\")\n",
        "        loss = loss.sum(dim=[1,2,3]).mean(dim=[0])\n",
        "        return loss\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
        "        # Using a scheduler is optional but can be helpful.\n",
        "        # The scheduler reduces the LR if the validation performance hasn't improved for the last N epochs\n",
        "        \n",
        "        \"\"\"scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,\n",
        "                                          base_lr=5e-5,\n",
        "                                          max_lr=1e-3,\n",
        "                                          step_size_up=(4*NUM_BATCHES_TRAIN)//2,\n",
        "                                          cycle_momentum=False,\n",
        "                                          mode=\"triangular2\")\"\"\"\n",
        "                                          \n",
        "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
        "                                                max_lr=1e-3,\n",
        "                                                total_steps=EPOCHS)\n",
        "        \n",
        "       \n",
        "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self._get_reconstruction_loss(batch)                             \n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss = self._get_reconstruction_loss(batch)\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "    \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        loss = self._get_reconstruction_loss(batch)\n",
        "        self.log('test_loss', loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVtkTOT-SjuT"
      },
      "source": [
        "### Training the model\n",
        "\n",
        "During the training, we want to keep track of the learning progress by seeing reconstructions made by our model. For this, we implement a callback object in PyTorch Lightning which will add reconstructions every $N$ epochs to our tensorboard:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BASYFYKSSjuT"
      },
      "outputs": [],
      "source": [
        "class GenerateCallback(pl.Callback):\n",
        "    \n",
        "    def __init__(self, input_imgs, every_n_epochs=1):\n",
        "        super().__init__()\n",
        "        self.input_imgs = input_imgs # Images to reconstruct during training\n",
        "        self.every_n_epochs = every_n_epochs # Only save those images every N epochs (otherwise tensorboard gets quite large)\n",
        "        \n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        if trainer.current_epoch % self.every_n_epochs == 0:\n",
        "            # Reconstruct images\n",
        "            input_imgs = self.input_imgs.to(pl_module.device)\n",
        "            with torch.no_grad():\n",
        "                pl_module.eval()\n",
        "                reconst_imgs = pl_module(input_imgs)\n",
        "                pl_module.train()\n",
        "            # Plot and add to tensorboard\n",
        "            imgs = torch.stack([input_imgs, reconst_imgs], dim=1).flatten(0,1)\n",
        "            grid = torchvision.utils.make_grid(imgs, nrow=2, normalize=True, range=(-1,1))\n",
        "            trainer.logger.experiment.add_image(\"Reconstructions\", grid, global_step=trainer.global_step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf3mLn_sSjuT"
      },
      "source": [
        "We will now write a training function that allows us to train the autoencoder with different latent dimensionality and returns both the test and validation score. We provide pre-trained models and recommend you using those, especially when you work on a computer without GPU. Of course, feel free to train your own models on Lisa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i3QFTao5SjuT"
      },
      "outputs": [],
      "source": [
        "def train_network(latent_dim, seed=24, linear_hidden_dims=[]):\n",
        "    \n",
        "    # Create a PyTorch Lightning trainer with the generation callback\n",
        "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, f\"MNIST_{latent_dim}_seed{seed}\"), \n",
        "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
        "                         devices=1,\n",
        "                         max_epochs=EPOCHS, \n",
        "                         callbacks=[ModelCheckpoint(save_weights_only=True),\n",
        "                                    GenerateCallback(get_train_images(8), every_n_epochs=10),\n",
        "                                    LearningRateMonitor(\"epoch\")])\n",
        "    \n",
        "    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
        "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
        "    \n",
        "    \n",
        "    model = LitAutoencoder(base_channel_size=28,\n",
        "                        latent_dim=latent_dim,\n",
        "                        seed=seed,\n",
        "                        linear_hidden_dims=linear_hidden_dims,\n",
        "                        num_input_channels=1, \n",
        "                        width=28, \n",
        "                        height=28\n",
        "                        )\n",
        "    trainer.fit(model, train_loader, val_loader)\n",
        "    \n",
        "    # Test best model on validation and test set\n",
        "    val_result = trainer.test(model, val_loader, verbose=False)\n",
        "    test_result = trainer.test(model, test_loader, verbose=False)\n",
        "    result = {\"test\": test_result, \"val\": val_result}\n",
        "    \n",
        "    return model, result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c473e7e9cab94517bb890b4b2c77203d",
            "39c6d1d876224d3fadc6e82a0de65e43",
            "d0afd3b8fb57479796f24c2d339c854c",
            "47231dd3a1e34dca821627274fe09bcc",
            "75c4849a9cfe4051a938988c15f6dfca",
            "eaafbfaf57144c6e8b0de481f7a9baf0",
            "584522243692481298047bce8411374f",
            "e09f36569ee243e99f2bad0be53f2904"
          ]
        },
        "id": "Ldg1mzLKSjuT",
        "outputId": "460d5403-c1ad-486c-f893-fa6c551101d4"
      },
      "outputs": [],
      "source": [
        "latent_dim = 2\n",
        "linear_hidden_dims = [512, 256, 128, 32]\n",
        "\n",
        "for seed in [200, 121, 2013, 2023]:\n",
        "    model_ld, result_ld = train_network(latent_dim, seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ja_LJ7AqSjuU"
      },
      "outputs": [],
      "source": [
        "def visualize_reconstructions(model, input_imgs):\n",
        "    # Reconstruct images\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        reconst_imgs = model(input_imgs.to(model.device))\n",
        "    reconst_imgs = reconst_imgs.cpu()\n",
        "    \n",
        "    # Plotting\n",
        "    imgs = torch.stack([input_imgs, reconst_imgs], dim=1).flatten(0,1)\n",
        "    grid = torchvision.utils.make_grid(imgs, nrow=4, normalize=True, range=(-1,1))\n",
        "    grid = grid.permute(1, 2, 0)\n",
        "    plt.figure(figsize=(7,4.5))\n",
        "    plt.title(f\"Reconstructed from {model.hparams.latent_dim} latents\")\n",
        "    plt.imshow(grid)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sOQxUpvnSjuU",
        "outputId": "6a06e3d6-8101-41e3-8f32-804a0108ff66"
      },
      "outputs": [
        {
          "data": {
            "application/pdf": "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\n",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"405pt\" height=\"227.491014pt\" viewBox=\"0 0 405 227.491014\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-03-21T21:18:57.757179</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 227.491014 \nL 405 227.491014 \nL 405 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g clip-path=\"url(#p8c30f63d37)\">\n    <image xlink:href=\"data:image/png;base64,\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\" id=\"image959c000c95\" transform=\"scale(1 -1)translate(0 -198.72)\" x=\"7.2\" y=\"-21.571014\" width=\"390.96\" height=\"198.72\"/>\n   </g>\n   <g id=\"text_1\">\n    <!-- Reconstructed from 2 latents -->\n    <g style=\"fill: #262626\" transform=\"translate(125.803125 15.789375)scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"ArialMT-52\" d=\"M 503 0 \nL 503 4581 \nL 2534 4581 \nQ 3147 4581 3465 4457 \nQ 3784 4334 3975 4021 \nQ 4166 3709 4166 3331 \nQ 4166 2844 3850 2509 \nQ 3534 2175 2875 2084 \nQ 3116 1969 3241 1856 \nQ 3506 1613 3744 1247 \nL 4541 0 \nL 3778 0 \nL 3172 953 \nQ 2906 1366 2734 1584 \nQ 2563 1803 2427 1890 \nQ 2291 1978 2150 2013 \nQ 2047 2034 1813 2034 \nL 1109 2034 \nL 1109 0 \nL 503 0 \nz\nM 1109 2559 \nL 2413 2559 \nQ 2828 2559 3062 2645 \nQ 3297 2731 3419 2920 \nQ 3541 3109 3541 3331 \nQ 3541 3656 3305 3865 \nQ 3069 4075 2559 4075 \nL 1109 4075 \nL 1109 2559 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-65\" d=\"M 2694 1069 \nL 3275 997 \nQ 3138 488 2766 206 \nQ 2394 -75 1816 -75 \nQ 1088 -75 661 373 \nQ 234 822 234 1631 \nQ 234 2469 665 2931 \nQ 1097 3394 1784 3394 \nQ 2450 3394 2872 2941 \nQ 3294 2488 3294 1666 \nQ 3294 1616 3291 1516 \nL 816 1516 \nQ 847 969 1125 678 \nQ 1403 388 1819 388 \nQ 2128 388 2347 550 \nQ 2566 713 2694 1069 \nz\nM 847 1978 \nL 2700 1978 \nQ 2663 2397 2488 2606 \nQ 2219 2931 1791 2931 \nQ 1403 2931 1139 2672 \nQ 875 2413 847 1978 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-63\" d=\"M 2588 1216 \nL 3141 1144 \nQ 3050 572 2676 248 \nQ 2303 -75 1759 -75 \nQ 1078 -75 664 370 \nQ 250 816 250 1647 \nQ 250 2184 428 2587 \nQ 606 2991 970 3192 \nQ 1334 3394 1763 3394 \nQ 2303 3394 2647 3120 \nQ 2991 2847 3088 2344 \nL 2541 2259 \nQ 2463 2594 2264 2762 \nQ 2066 2931 1784 2931 \nQ 1359 2931 1093 2626 \nQ 828 2322 828 1663 \nQ 828 994 1084 691 \nQ 1341 388 1753 388 \nQ 2084 388 2306 591 \nQ 2528 794 2588 1216 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-6f\" d=\"M 213 1659 \nQ 213 2581 725 3025 \nQ 1153 3394 1769 3394 \nQ 2453 3394 2887 2945 \nQ 3322 2497 3322 1706 \nQ 3322 1066 3130 698 \nQ 2938 331 2570 128 \nQ 2203 -75 1769 -75 \nQ 1072 -75 642 372 \nQ 213 819 213 1659 \nz\nM 791 1659 \nQ 791 1022 1069 705 \nQ 1347 388 1769 388 \nQ 2188 388 2466 706 \nQ 2744 1025 2744 1678 \nQ 2744 2294 2464 2611 \nQ 2184 2928 1769 2928 \nQ 1347 2928 1069 2612 \nQ 791 2297 791 1659 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-6e\" d=\"M 422 0 \nL 422 3319 \nL 928 3319 \nL 928 2847 \nQ 1294 3394 1984 3394 \nQ 2284 3394 2536 3286 \nQ 2788 3178 2913 3003 \nQ 3038 2828 3088 2588 \nQ 3119 2431 3119 2041 \nL 3119 0 \nL 2556 0 \nL 2556 2019 \nQ 2556 2363 2490 2533 \nQ 2425 2703 2258 2804 \nQ 2091 2906 1866 2906 \nQ 1506 2906 1245 2678 \nQ 984 2450 984 1813 \nL 984 0 \nL 422 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-73\" d=\"M 197 991 \nL 753 1078 \nQ 800 744 1014 566 \nQ 1228 388 1613 388 \nQ 2000 388 2187 545 \nQ 2375 703 2375 916 \nQ 2375 1106 2209 1216 \nQ 2094 1291 1634 1406 \nQ 1016 1563 777 1677 \nQ 538 1791 414 1992 \nQ 291 2194 291 2438 \nQ 291 2659 392 2848 \nQ 494 3038 669 3163 \nQ 800 3259 1026 3326 \nQ 1253 3394 1513 3394 \nQ 1903 3394 2198 3281 \nQ 2494 3169 2634 2976 \nQ 2775 2784 2828 2463 \nL 2278 2388 \nQ 2241 2644 2061 2787 \nQ 1881 2931 1553 2931 \nQ 1166 2931 1000 2803 \nQ 834 2675 834 2503 \nQ 834 2394 903 2306 \nQ 972 2216 1119 2156 \nQ 1203 2125 1616 2013 \nQ 2213 1853 2448 1751 \nQ 2684 1650 2818 1456 \nQ 2953 1263 2953 975 \nQ 2953 694 2789 445 \nQ 2625 197 2315 61 \nQ 2006 -75 1616 -75 \nQ 969 -75 630 194 \nQ 291 463 197 991 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-74\" d=\"M 1650 503 \nL 1731 6 \nQ 1494 -44 1306 -44 \nQ 1000 -44 831 53 \nQ 663 150 594 308 \nQ 525 466 525 972 \nL 525 2881 \nL 113 2881 \nL 113 3319 \nL 525 3319 \nL 525 4141 \nL 1084 4478 \nL 1084 3319 \nL 1650 3319 \nL 1650 2881 \nL 1084 2881 \nL 1084 941 \nQ 1084 700 1114 631 \nQ 1144 563 1211 522 \nQ 1278 481 1403 481 \nQ 1497 481 1650 503 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-72\" d=\"M 416 0 \nL 416 3319 \nL 922 3319 \nL 922 2816 \nQ 1116 3169 1280 3281 \nQ 1444 3394 1641 3394 \nQ 1925 3394 2219 3213 \nL 2025 2691 \nQ 1819 2813 1613 2813 \nQ 1428 2813 1281 2702 \nQ 1134 2591 1072 2394 \nQ 978 2094 978 1738 \nL 978 0 \nL 416 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-75\" d=\"M 2597 0 \nL 2597 488 \nQ 2209 -75 1544 -75 \nQ 1250 -75 995 37 \nQ 741 150 617 320 \nQ 494 491 444 738 \nQ 409 903 409 1263 \nL 409 3319 \nL 972 3319 \nL 972 1478 \nQ 972 1038 1006 884 \nQ 1059 663 1231 536 \nQ 1403 409 1656 409 \nQ 1909 409 2131 539 \nQ 2353 669 2445 892 \nQ 2538 1116 2538 1541 \nL 2538 3319 \nL 3100 3319 \nL 3100 0 \nL 2597 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-64\" d=\"M 2575 0 \nL 2575 419 \nQ 2259 -75 1647 -75 \nQ 1250 -75 917 144 \nQ 584 363 401 755 \nQ 219 1147 219 1656 \nQ 219 2153 384 2558 \nQ 550 2963 881 3178 \nQ 1213 3394 1622 3394 \nQ 1922 3394 2156 3267 \nQ 2391 3141 2538 2938 \nL 2538 4581 \nL 3097 4581 \nL 3097 0 \nL 2575 0 \nz\nM 797 1656 \nQ 797 1019 1065 703 \nQ 1334 388 1700 388 \nQ 2069 388 2326 689 \nQ 2584 991 2584 1609 \nQ 2584 2291 2321 2609 \nQ 2059 2928 1675 2928 \nQ 1300 2928 1048 2622 \nQ 797 2316 797 1656 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-66\" d=\"M 556 0 \nL 556 2881 \nL 59 2881 \nL 59 3319 \nL 556 3319 \nL 556 3672 \nQ 556 4006 616 4169 \nQ 697 4388 901 4523 \nQ 1106 4659 1475 4659 \nQ 1713 4659 2000 4603 \nL 1916 4113 \nQ 1741 4144 1584 4144 \nQ 1328 4144 1222 4034 \nQ 1116 3925 1116 3625 \nL 1116 3319 \nL 1763 3319 \nL 1763 2881 \nL 1116 2881 \nL 1116 0 \nL 556 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-6d\" d=\"M 422 0 \nL 422 3319 \nL 925 3319 \nL 925 2853 \nQ 1081 3097 1340 3245 \nQ 1600 3394 1931 3394 \nQ 2300 3394 2536 3241 \nQ 2772 3088 2869 2813 \nQ 3263 3394 3894 3394 \nQ 4388 3394 4653 3120 \nQ 4919 2847 4919 2278 \nL 4919 0 \nL 4359 0 \nL 4359 2091 \nQ 4359 2428 4304 2576 \nQ 4250 2725 4106 2815 \nQ 3963 2906 3769 2906 \nQ 3419 2906 3187 2673 \nQ 2956 2441 2956 1928 \nL 2956 0 \nL 2394 0 \nL 2394 2156 \nQ 2394 2531 2256 2718 \nQ 2119 2906 1806 2906 \nQ 1569 2906 1367 2781 \nQ 1166 2656 1075 2415 \nQ 984 2175 984 1722 \nL 984 0 \nL 422 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-32\" d=\"M 3222 541 \nL 3222 0 \nL 194 0 \nQ 188 203 259 391 \nQ 375 700 629 1000 \nQ 884 1300 1366 1694 \nQ 2113 2306 2375 2664 \nQ 2638 3022 2638 3341 \nQ 2638 3675 2398 3904 \nQ 2159 4134 1775 4134 \nQ 1369 4134 1125 3890 \nQ 881 3647 878 3216 \nL 300 3275 \nQ 359 3922 746 4261 \nQ 1134 4600 1788 4600 \nQ 2447 4600 2831 4234 \nQ 3216 3869 3216 3328 \nQ 3216 3053 3103 2787 \nQ 2991 2522 2730 2228 \nQ 2469 1934 1863 1422 \nQ 1356 997 1212 845 \nQ 1069 694 975 541 \nL 3222 541 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-6c\" d=\"M 409 0 \nL 409 4581 \nL 972 4581 \nL 972 0 \nL 409 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-61\" d=\"M 2588 409 \nQ 2275 144 1986 34 \nQ 1697 -75 1366 -75 \nQ 819 -75 525 192 \nQ 231 459 231 875 \nQ 231 1119 342 1320 \nQ 453 1522 633 1644 \nQ 813 1766 1038 1828 \nQ 1203 1872 1538 1913 \nQ 2219 1994 2541 2106 \nQ 2544 2222 2544 2253 \nQ 2544 2597 2384 2738 \nQ 2169 2928 1744 2928 \nQ 1347 2928 1158 2789 \nQ 969 2650 878 2297 \nL 328 2372 \nQ 403 2725 575 2942 \nQ 747 3159 1072 3276 \nQ 1397 3394 1825 3394 \nQ 2250 3394 2515 3294 \nQ 2781 3194 2906 3042 \nQ 3031 2891 3081 2659 \nQ 3109 2516 3109 2141 \nL 3109 1391 \nQ 3109 606 3145 398 \nQ 3181 191 3288 0 \nL 2700 0 \nQ 2613 175 2588 409 \nz\nM 2541 1666 \nQ 2234 1541 1622 1453 \nQ 1275 1403 1131 1340 \nQ 988 1278 909 1158 \nQ 831 1038 831 891 \nQ 831 666 1001 516 \nQ 1172 366 1500 366 \nQ 1825 366 2078 508 \nQ 2331 650 2450 897 \nQ 2541 1088 2541 1459 \nL 2541 1666 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#ArialMT-52\"/>\n     <use xlink:href=\"#ArialMT-65\" x=\"72.216797\"/>\n     <use xlink:href=\"#ArialMT-63\" x=\"127.832031\"/>\n     <use xlink:href=\"#ArialMT-6f\" x=\"177.832031\"/>\n     <use xlink:href=\"#ArialMT-6e\" x=\"233.447266\"/>\n     <use xlink:href=\"#ArialMT-73\" x=\"289.0625\"/>\n     <use xlink:href=\"#ArialMT-74\" x=\"339.0625\"/>\n     <use xlink:href=\"#ArialMT-72\" x=\"366.845703\"/>\n     <use xlink:href=\"#ArialMT-75\" x=\"400.146484\"/>\n     <use xlink:href=\"#ArialMT-63\" x=\"455.761719\"/>\n     <use xlink:href=\"#ArialMT-74\" x=\"505.761719\"/>\n     <use xlink:href=\"#ArialMT-65\" x=\"533.544922\"/>\n     <use xlink:href=\"#ArialMT-64\" x=\"589.160156\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"644.775391\"/>\n     <use xlink:href=\"#ArialMT-66\" x=\"672.558594\"/>\n     <use xlink:href=\"#ArialMT-72\" x=\"700.341797\"/>\n     <use xlink:href=\"#ArialMT-6f\" x=\"733.642578\"/>\n     <use xlink:href=\"#ArialMT-6d\" x=\"789.257812\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"872.558594\"/>\n     <use xlink:href=\"#ArialMT-32\" x=\"900.341797\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"955.957031\"/>\n     <use xlink:href=\"#ArialMT-6c\" x=\"983.740234\"/>\n     <use xlink:href=\"#ArialMT-61\" x=\"1005.957031\"/>\n     <use xlink:href=\"#ArialMT-74\" x=\"1061.572266\"/>\n     <use xlink:href=\"#ArialMT-65\" x=\"1089.355469\"/>\n     <use xlink:href=\"#ArialMT-6e\" x=\"1144.970703\"/>\n     <use xlink:href=\"#ArialMT-74\" x=\"1200.585938\"/>\n     <use xlink:href=\"#ArialMT-73\" x=\"1228.369141\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p8c30f63d37\">\n   <rect x=\"7.2\" y=\"21.789375\" width=\"390.6\" height=\"198.501639\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<Figure size 700x450 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "input_imgs = get_train_images(4)\n",
        "visualize_reconstructions(model_ld, input_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9dkyZhySjuV"
      },
      "source": [
        "### Tensorboard clustering\n",
        "\n",
        "Another way of exploring the similarity of images in the latent space is by dimensionality-reduction methods like PCA or T-SNE. Luckily, Tensorboard provides a nice interface for this and we can make use of it in the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LUA02LaoSjuW"
      },
      "outputs": [],
      "source": [
        "# Create a summary writer\n",
        "writer = SummaryWriter(\"tensorboard/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnkVuCwnSjuW"
      },
      "source": [
        "The function `add_embedding` allows us to add high-dimensional feature vectors to TensorBoard on which we can perform clustering. What we have to provide in the function are the feature vectors, additional metadata such as the labels, and the original images so that we can identify a specific image in the clustering. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6DO__ekSjuW"
      },
      "outputs": [],
      "source": [
        "## In case you obtain the following error in the next cell, execute the import statements and last line in this cell\n",
        "##   AttributeError: module 'tensorflow._api.v2.io.gfile' has no attribute 'get_filesystem'\n",
        "\n",
        "# import tensorflow as tf\n",
        "# import tensorboard as tb\n",
        "# tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UvwLfd5SjuW"
      },
      "outputs": [],
      "source": [
        "# Note: the embedding projector in tensorboard is computationally heavy.\n",
        "# Reduce the image amount below if your computer struggles with visualizing all 10k points\n",
        "NUM_IMGS = len(test_set) \n",
        "\n",
        "writer.add_embedding(test_img_embeds[1][:NUM_IMGS], # Encodings per image\n",
        "                     metadata=[test_set[i][1] for i in range(NUM_IMGS)], # Adding the labels per image to the plot\n",
        "                     label_img=(test_img_embeds[0][:NUM_IMGS]+1)/2.0) # Adding the original images to the plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtbLHDERSjuW"
      },
      "source": [
        "Finally, we can run tensorboard to explore similarities among images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wZqzeomUSjuW"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir saved_models/ae_sim/MNIST_2/lightning_logs/version_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd5Q3zFwSjuW"
      },
      "source": [
        "You should be able to see something similar as in the following image. In case the projector stays empty, try to start the TensorBoard outside of the Jupyter notebook.\n",
        "\n",
        "<center><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial9/tensorboard_projector_screenshot.jpeg?raw=1\" width=\"70%\"/></center>\n",
        "\n",
        "Overall, we can see that the model indeed clustered images together that are visually similar. Especially the background color seems to be a crucial factor in the encoding. This correlates to the chosen loss function, here Mean Squared Error on pixel-level because the background is responsible for more than half of the pixels in an average image. Hence, the model learns to focus on it. Nevertheless, we can see that the encodings also separate a couple of classes in the latent space although it hasn't seen any labels. This shows again that autoencoding can also be used as a \"pre-training\"/transfer learning task before classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoofiHxOSjuW"
      },
      "outputs": [],
      "source": [
        "# Closing the summary writer\n",
        "writer.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
