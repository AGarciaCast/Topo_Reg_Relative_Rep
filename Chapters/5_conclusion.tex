\documentclass[../main.tex]{subfiles}
\begin{document}

\chapter{Discussion}
\label{ch:discussion}

In this chapter, we will engage in further analysis, offering additional insights, opinions, and hypotheses concerning the methodology and the results obtained in this project.

\section{Similarities beyond intertwiner group actions}
\label{sec:more_sim}

As previously mentioned, we acknowledge that the observed $\epsilon$-similarities are not exclusively generated by the actions of the intertwiner group. This claim is supported by two key points:
\begin{itemize}
    \item In Section~\ref{sec:res_lat}, we computed the Frobenius distance between the optimal orthogonal and optimal permutation Procrustes transformations. It is important to recall that we did not observe small distances between these matrices, which prevents us from conclusively attributing the source of the $\epsilon$-similarity to the intertwiner group associated with the GeLU activation function used in RoBERTa models.

     \item In the original paper introducing the intertwiner group \cite{godfrey_symmetries_2023}, a variant of the CKA metric called CKA-ReLU was developed. This variant is designed to yield high similarities between latent spaces if the differences arise from a ReLU intertwiner group's action. Using this new metric, the authors found that in later layers, the CKA-ReLU decreases while the standard CKA remains unchanged. This additional empirical evidence suggests that other factors may contribute to the observed $\epsilon$-similarity.
\end{itemize}

However, despite these observations, we believe that establishing a theoretical foundation for the relative transformation is still crucial. We now understand that if the $\epsilon$-similarity arises from the intertwiner group, our transformation will be invariant to it. Furthermore, even if the $\epsilon$-similarity originates from another source, as mentioned in \cite{moschella_relative_2022}, our transformation will still maintain invariance, although lacking a rigorous theoretical proof.


\section{Post-relative geometry}
In the previous chapter, we observed that applying Hofer's topological regularization in the post-relative space posed more challenges compared to the pre-relative space. One of the reasons identified was the significant influence of the anchors on the post-relative geometry. To illustrate the importance of anchors in supporting this claim, we provide the following proposition:

\begin{proposition}
Let $\Anch\in \RR^{d \times k}$ be the matrix representation of the (normalized) images of the anchor set $\mathcal{A}$, and let $z_1, z_2 \in \mathcal{Z}$ be the (normalized) images of samples $x_1, x_2 \in \mathcal{X}$. Then,
\[
\norm{\Anch^T\frac{z_1}{\norm{z_1}} - \Anch^T\frac{z_2}{\norm{z_2}}}^2 \leq 2(\max \lambda - \min \sigma)\,,
\]
where $\lambda$ and $\sigma$ are, respectively, the eigenvalues and singular values of $\Anch\Anch^T$.
\end{proposition}
\begin{proof}
    \begin{align*}
        \norm{\Anch^T\frac{z_1}{\norm{z_1}} - \Anch^T\frac{z_2}{\norm{z_2}}}^2 &= \left(\frac{z_1^T}{\norm{z_1}}\Anch - \frac{z_2^T}{\norm{z_2}}\Anch\right)\left(\Anch^T\frac{z_1}{\norm{z_1}} - \Anch^T\frac{z_2}{\norm{z_2}}\right)\\
        &=\frac{z_1^T\Anch\Anch^Tz_1}{\norm{z_1}^2} -2\frac{z_1^T\Anch\Anch^Tz_2}{\norm{z_1}\norm{z_2}}+ \frac{z_2^T\Anch\Anch^Tz_2}{\norm{z_2}^2}\\
        &\leq 2(\max \lambda - \min \sigma)\,.
    \end{align*}
The final step follows from the properties of Rayleigh's quotient.
\end{proof}

Hence, we can see that an upper bound on the diameter of the relative transformation is solely determined by the anchors.


\section{Topological regularization overview}
\label{sec:more_topo}

\subsection{High computational complexity}
As we have seen, Hofer's topological regularization requires a specific dataloader which does not work as originally presented when we use gradient accumulation and the robust relative transformation. To address this issue, we employed the freezing/unfreezing technique, extensively discussed in Section~\ref{sec:topo_meth}. However, it is worth noting that this fix led to slightly inferior results compared to the vanilla case.\\

The scalability concern we encountered is not exclusive to Hofer's regularization; several topological data analysis (TDA) methods face similar challenges. For instance, the standard algorithm for computing Persistent Homology has a complexity that scales cubically with the number of simplices \cite{akcora_reduction_2022}. Consequently, current practice often restricts the analysis to $\text{H}_0$ and $\text{H}_1$ since computing higher homologies on large datasets can take weeks. Nevertheless, due to the growing interest in TDA, recent research has aimed to enhance the scalability of various TDA methods \cite{akcora_reduction_2022, polianskii_breaking_2022}.\\

Therefore, we believe that if there starts to have an increase in the visibility of topological regularization techniques, it would be required to optimize existing methods or develop new ones that are better suited for modern large-scale neural network architectures.

\subsection{Strong regularization}

During the hyperparameter tuning phase, we made an interesting observation regarding Hofer's topological regularization. It had a significant impact in mitigating overfitting, but the regularization effect was so pronounced that it led to inferior classification performance compared to not using the regularization. To address this issue, we employed the cyclical linear scheduler for the loss's weight component $\lambda$. This approach resulted in densified distributions that still yielded satisfactory performance for the classification task.\\


We believe that the reason why we could not successfully apply Hofer's topological regularization to the Spanish case as well as why the ``en-fr'' stitching case does not perform as well as ``fr-en'', is that both the French and Spanish models had less expressiveness than the English model. Hence applying a ``demanding'' regularization prevents the network from obtaining a proper latent space for the classification class. In other words, we encounter an imbalance in the bias-variance tradeoff, with excessive bias hampering the network's performance.


\subsection{Beyond the Vietoris–Rips complex}
As observed in our experiments, the use of different metrics for computing the 0-dimensional Vietoris–Rips persistent homology can have some benefits compared to using the standard $L^2$ metric.

In addition, we believe that employing diverse simplicial complexes for the computation of Hofer's topological regularization can yield interesting insights. For example, utilizing Lazy Witness complexes appears to be well-suited for the post-relative space (see Definition \ref{def:witness}). This choice is motivated by the fact that Witness complexes capture the data's topology from the perspective of the witnesses, while the relative transformations look at the geometry of the data through the anchors.\\

Furthermore, based on Proposition~\ref{prop:witness-vr}, we can know the relations between the $H_0$ homology of a Witness complex, and the $\epsilon$-connectivity:
\begin{corollary}
Let $X\subset \RR^n$, and $\dag(X)$ the $\text{\rm H}_0$ persistent homology death times of a Witness complex filtration of $X$. Then,
\begin{itemize}
    \item If $\max \dag(X) < \epsilon \implies 2\epsilon$-connected.
    \item If $2\epsilon$-connected $\notimplies \max \dag(X) < \epsilon$.
    \item If $2\epsilon$-connected $\implies \max \dag(X) < 2\epsilon$.
\end{itemize}
\end{corollary}





\cleardoublepage
\chapter{Conclusions and Future work}
\label{ch:conclusionsAndFutureWork}


\section{Conclusions}
\label{sec:conclusions}
\sweExpl{Slutsatser}
\engExpl{Describe the conclusions (reflect on the whole introduction given in Chapter 1).}


  
\engExpl{Discuss the positive effects and the drawbacks.\\
Describe the evaluation of the results of the degree project.\\
Did you meet your goals?\\
What insights have you gained?\\
What suggestions can you give to others working in this area?\\
If you had it to do again, what would you have done differently?}

\sweExpl{Uppfyllde du dina mål?\\
Vilka insikter har du fått?\\
Vilka förslag kan du ge till andra som arbetar inom detta område?
Om du skulle göra detta igen, vad skulle du ha gjort annorlunda?}

\section{Limitations}
\label{sec:limitations}
\sweExpl{Begränsande faktorer\\Vad gjorde du som begränsade dina ansträngningar? Vilka är begränsningarna i dina resultat?}
\engExpl{What did you find that limited your efforts? What are the limitations of your results?}


\section{Future work}
\label{sec:futureWork}
\sweExpl{Vad du har kvar ogjort?\\Vad är nästa självklara saker som ska göras?\\Vad tips kan du ge till nästa person som kommer att följa upp på ditt arbete?}
\engExpl{Describe valid future work that you or someone else could or should do.\\
Consider: What you have left undone? What are the next obvious things to be done? What hints can you give to the next person who is going to follow up on your work?}



Due to the breadth of the problem, only some of the initial goals have been
met. In these section we will focus on some of the remaining issues that
should be addressed in future work. ...

\subsection{What has been left undone?}
\label{what-has-been-left-undone}

The prototype does not address the third requirment, \ie a yearly unavailability of less than 3 minutes, this remains an open problem. ...




\subsection{Next obvious things to be done}

In particular, the author of this thesis wishes to point out xxxxxx remains as a problem to be solved. Solving this problem is the next thing that should be done. ...

\section{Reflections}
\label{sec:reflections}
\sweExpl{Reflektioner}
\sweExpl{Vilka är de relevanta ekonomiska, sociala, miljömässiga och etiska aspekter av ditt arbete?}
\engExpl{What are the relevant economic, social,
  environmental, and ethical aspects of your work?
}



One of the most important results is the reduction in the amount of
energy required to process each packet while at the same time reducing the
time required to process each packet.

The thesis contributes to the  numbers 1 and 9 by
xxxx. 



\end{document}